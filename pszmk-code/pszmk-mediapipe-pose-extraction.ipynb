{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from typing import Tuple\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "GENERAL_DATA_PATH = Path(current_working_dir) / 'data'\n",
    "DATA_PATH = GENERAL_DATA_PATH\n",
    "\n",
    "with open(DATA_PATH / 'keypoints_names.pkl', 'rb') as file:\n",
    "    KEYPOINTS_NAMES = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_numpy(image_file_name : str) -> np.ndarray:\n",
    "    return np.array(Image.open(DATA_PATH / 'train' / image_file_name))\n",
    "\n",
    "def get_random_image_numpy() -> np.ndarray:\n",
    "    images = os.listdir(DATA_PATH / 'train')\n",
    "    random_image_file_name = random.choice(images)\n",
    "    return get_image_numpy(random_image_file_name)\n",
    "\n",
    "class PoseExtractor():\n",
    "    keypoints_names = KEYPOINTS_NAMES.copy()\n",
    "    extraction_output_len = 132\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            source_data_path : str,\n",
    "            destination_data_path : str,\n",
    "            model_complexity : int,\n",
    "            min_detection_confidence : float = 0.5\n",
    "            ) -> None:\n",
    "        self.source_data_path = Path(source_data_path)\n",
    "        self.destination_data_path = Path(destination_data_path)\n",
    "        self.pose = mp.solutions.pose.Pose(\n",
    "            static_image_mode=True,\n",
    "            model_complexity=model_complexity,\n",
    "            smooth_landmarks=True,\n",
    "            enable_segmentation=False,\n",
    "            smooth_segmentation=False,\n",
    "            min_detection_confidence=min_detection_confidence,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def columns_names(self) -> np.ndarray:\n",
    "        columns_names = []\n",
    "        \n",
    "        for keypoint_name in self.keypoints_names:\n",
    "            columns_names.extend([f'{keypoint_name}_x', f'{keypoint_name}_y', f'{keypoint_name}_z', f'{keypoint_name}_visibility'])\n",
    "\n",
    "        return columns_names\n",
    "\n",
    "    def load_image_as_ndarray(\n",
    "            self,\n",
    "            image_file_name : str,\n",
    "            train : bool\n",
    "            ) -> np.ndarray:\n",
    "        if train:\n",
    "            dataset_type = 'train'\n",
    "        else:\n",
    "            dataset_type = 'test'\n",
    "\n",
    "        return np.array(Image.open(self.source_data_path / dataset_type / image_file_name))\n",
    "\n",
    "    def extract_pose(\n",
    "            self,\n",
    "            image: np.ndarray\n",
    "            ) -> Tuple:\n",
    "        extraction_res = self.pose.process(image).pose_landmarks\n",
    "        \n",
    "        if extraction_res is None:\n",
    "            return [None for _ in range(4 * self.extraction_output_len)]\n",
    "\n",
    "        return list(np.hstack([np.array([landmark.x, landmark.y, landmark.z, landmark.visibility], dtype=np.float64) for landmark in extraction_res.landmark]))\n",
    "    \n",
    "    def extract_poses_and_write_to_csv(\n",
    "            self,\n",
    "            save_file_name : str,\n",
    "            sample : bool,\n",
    "            n_samples : int,\n",
    "            train : bool = True\n",
    "            ) -> None:\n",
    "        if train:\n",
    "            images = os.listdir(self.source_data_path / 'train')\n",
    "        else:\n",
    "            images = os.listdir(self.source_data_path / 'test')\n",
    "        \n",
    "        if sample:\n",
    "            images = random.sample(images, n_samples)\n",
    "        \n",
    "        with open(self.destination_data_path / save_file_name, 'w') as write_file:\n",
    "            writer = csv.writer(write_file, delimiter=';')\n",
    "            writer.writerow(self.columns_names)\n",
    "            \n",
    "            data_rows = []\n",
    "            \n",
    "            for image_filename in images:\n",
    "                image = self.load_image_as_ndarray(image_filename, train)\n",
    "                data_rows.append(self.extract_pose(image))\n",
    "            \n",
    "            writer.writerows(data_rows)   \n",
    "            return data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_extractor = PoseExtractor(\n",
    "    source_data_path=DATA_PATH,\n",
    "    destination_data_path=GENERAL_DATA_PATH,\n",
    "    model_complexity=1\n",
    ")\n",
    "\n",
    "# image = get_image_numpy('01300.jpg')\n",
    "# landmarks = pose_extractor.extract_pose(image)\n",
    "# print(landmarks.shape, len(pose_extractor.columns_names[0]))\n",
    "# for landmark in landmarks:\n",
    "#     print(landmark)\n",
    "# print(pose_extractor.columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows = pose_extractor.extract_poses_and_write_to_csv(\n",
    "    sample=True,\n",
    "    n_samples=1,\n",
    "    train=True,\n",
    "    save_file_name='train-poses.csv',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to try-out.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Example data to write to CSV file\n",
    "data = [\n",
    "    list(*np.random.rand(1, 3)),\n",
    "    list(*np.random.rand(1, 3)),\n",
    "    list(*np.random.rand(1, 3))\n",
    "]\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'try-out.csv'\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write multiple rows to the CSV file\n",
    "    csvwriter.writerows(data)\n",
    "\n",
    "print(\"Data has been written to\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from typing import Tuple, List, Union\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir: str):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_files = os.listdir(data_dir)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def get_label(self, img_name: str) -> int:\n",
    "        # Extract the label from the image name (assuming it's the first digit)\n",
    "        label = int(img_name[0])  # Convert the first character to an integer\n",
    "        return label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_name = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        image = cv2.imread(img_name)  # Read image using OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        tensor_image = self.transform(image)\n",
    "        label = self.get_label(self.image_files[idx])\n",
    "\n",
    "        # Save the preprocessed image to the \"NewTrain\" folder\n",
    "        save_path = os.path.join(\"NewTrain\", f\"preprocessed_{self.image_files[idx]}\")\n",
    "        if tensor_image.shape[0] == 1:\n",
    "            # If it's a single-channel image, convert it to three channels before saving\n",
    "            tensor_image_rgb = torch.cat([tensor_image] * 3, dim=0)\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(tensor_image_rgb.numpy().transpose(1, 2, 0), cv2.COLOR_RGB2BGR))\n",
    "        else:\n",
    "            # If it's already a three-channel image, save as is\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(tensor_image.numpy().transpose(1, 2, 0), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "        return tensor_image, label\n",
    "\n",
    "# Example usage:\n",
    "data_directory = \"Train\"\n",
    "custom_dataset = CustomDataset(data_directory)\n",
    "\n",
    "# Example loading one image\n",
    "sample_image, label = custom_dataset[2]\n",
    "file = os.listdir(data_directory)\n",
    "print(file[2])\n",
    "print(sample_image.shape)  # Check the shape (should be torch.Size([1, 224, 224]))\n",
    "print(\"Label:\", label)\n",
    "print(sample_image)\n",
    "\n",
    "min_value = torch.min(sample_image)\n",
    "max_value = torch.max(sample_image)\n",
    "\n",
    "print(\"Minimum value:\", min_value.item())\n",
    "print(\"Maximum value:\", max_value.item())\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "numpy_image = sample_image.squeeze().numpy()\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(numpy_image, cmap='gray')  # Use 'gray' colormap for single-channel images\n",
    "plt.title(\"Image Title\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pose.__init__() got an unexpected keyword argument 'num_poses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image_np \u001b[38;5;241m=\u001b[39m get_random_image_numpy()\n\u001b[1;32m----> 3\u001b[0m pose \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_poses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mprocess(image_np)\u001b[38;5;66;03m#cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark  \u001b[38;5;66;03m# List of normalized keypoints (x, y, z)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Pose.__init__() got an unexpected keyword argument 'num_poses'"
     ]
    }
   ],
   "source": [
    "image_np = get_random_image_numpy()\n",
    "\n",
    "pose = mp.solutions.pose.Pose(\n",
    "            num_poses=1,\n",
    "            min_detection_confidence=0.5\n",
    "            )\n",
    "\n",
    "results = pose.process(image_np)#cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "keypoints = results.pose_landmarks.landmark  # List of normalized keypoints (x, y, z)\n",
    "\n",
    "feature_vector = np.array([kp.x for kp in keypoints] + [kp.y for kp in keypoints] + [kp.z for kp in keypoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.2824716\n",
       "y: 0.43324316\n",
       "z: 0.058916435\n",
       "visibility: 0.9987006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose-estimation-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
